{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47f8c053-1e65-45aa-bf26-2bb1d466a378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "577d4283-b8d2-4e67-8583-027b6bfc5247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# Adjust encoding if necessary, depending on the data's format\n",
    "data = pd.read_csv('Copy of Sentiment.csv', encoding='ISO-8859-1')  # Use 'latin-1', 'ISO-8859-1' or encoding='cp1252'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2c652f-dc5f-412b-b799-c72b5117b43c",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b08411b-6457-4f90-9d04-7542788a935e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN (missing) values in 'text' column with empty strings\n",
    "# This ensures all values are strings and prevents errors when applying text operations\n",
    "data['text'] = data['text'].fillna('').astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1761eed5-4816-43f3-9368-bd9fbd13e549",
   "metadata": {},
   "source": [
    "# Convert text to lowercase to normalize the data for text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "757e8803-ae42-4b97-a23d-0294436e43d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We apply this to the 'text' column\n",
    "data['text'] = data['text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4100e40-2230-49bf-a0f4-3132ebde215e",
   "metadata": {},
   "source": [
    "# Tokenization - Convert the text data into sequences of tokens (words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "386df058-7d7e-43ed-aa14-c168fb7fe145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we use the 'text' column for sentiment analysis\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ffae52d6-28ff-4df7-b3bf-a30b4ea03411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert texts to sequences of integers\n",
    "sequences = tokenizer.texts_to_sequences(data['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126e1c5f-6282-4633-8edb-3eaaaba48160",
   "metadata": {},
   "source": [
    "# Padding - Ensure all sequences are of the same length for model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4dd6a574-d693-42ab-8726-9ab9ffbce4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to the maximum length, truncating longer ones and padding shorter ones\n",
    "padded_sequences = pad_sequences(sequences, maxlen=50, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8fb3ef-27df-4859-97b8-0924e682598d",
   "metadata": {},
   "source": [
    "# Label Encoding - Convert the 'sentiment' column (target variable) into numeric labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "58dc18e8-fc6a-471a-81a0-e544c2cebc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is necessary because machine learning models can't work directly with text labels\n",
    "sentiment_mapping = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
    "data['sentiment'] = data['sentiment'].map(sentiment_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "283b0a6f-ca72-4432-b550-5a35c0d95de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target variable (sentiment) into NumPy array\n",
    "labels = np.array(data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76d2975-759e-4d4a-bf2b-7c57162ebd45",
   "metadata": {},
   "source": [
    "# Train-Test Split - Split the data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "adf6159e-f35b-49bb-b471-b606dce4edec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80% training and 20% test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df652a2-1ca4-46ce-b878-a5ae78f500e0",
   "metadata": {},
   "source": [
    "# Build the GRU model for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e4552fbb-16ca-4a1e-90d7-9074cc5aed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Embedding layer to convert word indices into dense vectors of fixed size\n",
    "model.add(Embedding(input_dim=10000, output_dim=64))\n",
    "\n",
    "# GRU layer for sequential processing of text data\n",
    "model.add(GRU(64, return_sequences=False))\n",
    "\n",
    "# Add a Dropout layer to prevent overfitting\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Dense layer for output\n",
    "model.add(Dense(3, activation='softmax'))  # Output layer for 3 classes: positive, neutral, negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d935b21-07a6-4386-8c60-ba131032d853",
   "metadata": {},
   "source": [
    "# Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d8c3a707-e324-4580-9565-2700154c33c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use categorical crossentropy for multi-class classification and Adam optimizer\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abff0bb-e80b-4d2f-b88e-b1ee0fb1a1ef",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7ba6bd08-44da-4566-ab3a-9981b581c654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 33ms/step - accuracy: 0.3970 - loss: 1.0916 - val_accuracy: 0.4057 - val_loss: 1.0894\n",
      "Epoch 2/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 31ms/step - accuracy: 0.4062 - loss: 1.0887 - val_accuracy: 0.4057 - val_loss: 1.0867\n",
      "Epoch 3/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 32ms/step - accuracy: 0.4090 - loss: 1.0865 - val_accuracy: 0.4057 - val_loss: 1.0872\n",
      "Epoch 4/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 35ms/step - accuracy: 0.4090 - loss: 1.0866 - val_accuracy: 0.4057 - val_loss: 1.0872\n",
      "Epoch 5/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - accuracy: 0.4039 - loss: 1.0878 - val_accuracy: 0.4057 - val_loss: 1.0871\n",
      "Epoch 6/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 32ms/step - accuracy: 0.4028 - loss: 1.0882 - val_accuracy: 0.4057 - val_loss: 1.0872\n",
      "Epoch 7/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 31ms/step - accuracy: 0.4066 - loss: 1.0870 - val_accuracy: 0.4057 - val_loss: 1.0867\n",
      "Epoch 8/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 32ms/step - accuracy: 0.4018 - loss: 1.0882 - val_accuracy: 0.4057 - val_loss: 1.0868\n",
      "Epoch 9/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 31ms/step - accuracy: 0.4057 - loss: 1.0869 - val_accuracy: 0.4057 - val_loss: 1.0869\n",
      "Epoch 10/10\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - accuracy: 0.4082 - loss: 1.0866 - val_accuracy: 0.4057 - val_loss: 1.0867\n"
     ]
    }
   ],
   "source": [
    "# Train for 10 epochs with a batch size of 32\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7a9518-80b7-4b96-877b-dd7001f15e63",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "65bb6d59-8a02-4071-80d8-21c343d4c57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4091 - loss: 1.0860\n",
      "Test Accuracy: 0.40567582845687866\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance of the model on the test data\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ba4a5e-aba8-4f19-af61-ec0909c5d02c",
   "metadata": {},
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "57903840-e4e5-4880-9e32-8c0e23af4ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict sentiment on new data (X_test as example)\n",
    "predictions = model.predict(X_test)\n",
    "predicted_classes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "accc1936-5188-4c5b-816f-f38d014b9ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  i`d have responded, if i were going\n",
      "True Sentiment: 2, Predicted Sentiment: 1\n",
      "\n",
      "Text:  sooo sad i will miss you here in san diego!!!\n",
      "True Sentiment: 1, Predicted Sentiment: 1\n",
      "\n",
      "Text: my boss is bullying me...\n",
      "True Sentiment: 1, Predicted Sentiment: 1\n",
      "\n",
      "Text:  what interview! leave me alone\n",
      "True Sentiment: 0, Predicted Sentiment: 1\n",
      "\n",
      "Text:  sons of ****, why couldn`t they put them on the releases we already bought\n",
      "True Sentiment: 2, Predicted Sentiment: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show some predictions\n",
    "for i in range(5):\n",
    "    print(f\"Text: {data['text'][i]}\")\n",
    "    print(f\"True Sentiment: {y_test[i]}, Predicted Sentiment: {predicted_classes[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e103ac7-51b3-47dd-8a14-1e6c25521fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
